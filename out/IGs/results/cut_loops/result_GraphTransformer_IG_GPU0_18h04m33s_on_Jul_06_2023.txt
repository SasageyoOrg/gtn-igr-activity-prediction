Dataset: IG,
Model: GraphTransformer

params={'seed': 11, 'epochs': 200, 'batch_size': 256, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 1, 'max_time': 24}

net_params={'L': 4, 'n_heads': 4, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'lap_pos_enc': True, 'pos_enc_dim': 20, 'wl_pos_enc': True, 'full_graph': True, 'device': device(type='cuda'), 'gpu_id': 0, 'batch_size': 256, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 16, 'total_param': 142464}

GraphTransformerNet(
  (embedding_lap_pos_enc): Linear(in_features=20, out_features=64, bias=True)
  (embedding_wl_pos_enc): Embedding(77, 64)
  (embedding_h): Embedding(1, 64)
  (in_feat_dropout): Dropout(p=0.0, inplace=False)
  (embedding_e): Linear(in_features=1, out_features=64, bias=True)
  (layers): ModuleList(
    (0): GraphTransformerLayer(in_channels=64, out_channels=64, heads=4, residual=True)
    (1): GraphTransformerLayer(in_channels=64, out_channels=64, heads=4, residual=True)
    (2): GraphTransformerLayer(in_channels=64, out_channels=64, heads=4, residual=True)
    (3): GraphTransformerLayer(in_channels=64, out_channels=64, heads=4, residual=True)
  )
  (MLP_layer): MLPReadout(
    (FC_layers): ModuleList(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): Linear(in_features=32, out_features=16, bias=True)
      (2): Linear(in_features=16, out_features=16, bias=True)
    )
  )
)

Total Parameters: 142464


    FINAL RESULTS
TEST ACCURACY: 0.6425
TRAIN ACCURACY: 0.6456


    Convergence Time (Epochs): 151.0000
Total Time Taken: 2.2954 hrs
Average Time Per Epoch: 51.2177 s


